{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Compute SESAME inverse solution on evoked data with given source location prior\n\nIn this example we shall apply SESAME on an evoked dataset,\ncorresponding to the response to an auditory stimulus and we manually select a priori source location\nprobability to reside in a subset of ROIs in a given brain parcellization.\nData are taken from the MNE-Python\n[sample](https://mne.tools/stable/generated/mne.datasets.sample.data_path.html#mne.datasets.sample.data_path)\ndataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Gianvittorio Luria <luria@dima.unige.it>\n#          Sara Sommariva <sommariva@dima.unige.it>\n#          Alberto Sorrentino <sorrentino@dima.unige.it>\n#\n# License: BSD (3-clause)\n\n# sphinx_gallery_thumbnail_number = 2\n\nfrom os import path as op\nimport matplotlib.pyplot as plt\nfrom mne.datasets import sample\nfrom mne import read_forward_solution, pick_types_forward, read_evokeds\nfrom sesameeg.utils import prior_loc_from_labels\nfrom sesameeg.mne import prepare_sesame\n\n\ndata_path = sample.data_path()\nsubject = 'sample'\nsubjects_dir = op.join(data_path, 'subjects')\nfname_fwd = op.join(data_path, 'MEG', subject,\n                    'sample_audvis-meg-eeg-oct-6-fwd.fif')\nfname_evoked = op.join(data_path, 'MEG', subject, 'sample_audvis-ave.fif')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the forward solution  $\\textbf{G}$  and the evoked data\n$\\textbf{y}$.\nThe forward solution also defines the employed brain discretization.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "meg_sensor_type = True  # All MEG sensors will be included\neeg_sensor_type = False\n\n# Forward solution\nfwd = read_forward_solution(fname_fwd, exclude='bads')\nfwd = pick_types_forward(fwd, meg=meg_sensor_type,\n                         eeg=eeg_sensor_type, ref_meg=False)\n\n# Evoked Data\ncondition = 'Left Auditory'\nevoked = read_evokeds(fname_evoked, condition=condition, baseline=(None, 0))\nevoked = evoked.pick('meg', exclude='bads')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the parameters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "time_min, time_max = 0.045, 0.135  # Select N100m\nsubsample = None\nsample_min, sample_max = evoked.time_as_index([time_min, time_max],\n                                              use_rounding=True)\n\n# To accelerate the run time of this example, we use a small number of\n# particles. We recall that the parameter ``n_parts`` represents, roughly speaking,\n# the number of candidate solutions that are tested in the Monte Carlo procedure;\n# larger values yield in principle more accurate reconstructions but also entail a\n# higher computational cost. Setting the value to about a hundred seems to represent\n# a good trade\u2013off.\nn_parts = 10\n# If None, noise_std and dip_mom_std will be estimated by SESAME.\nnoise_std = None\ndip_mom_std = None\n\n\nnoise_cov = None\n# You can make SESAME pre-whiten the data by providing a noise covariance\n# from mne import read_cov\n# fname_cov = op.join(sample.data_path(), 'MEG', subject,\n#                    'sample_audvis-cov.fif')\n# noise_cov = read_cov(fname_cov)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A priori select some ROIs\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "prior_rois = prior_loc_from_labels(subject, subjects_dir, fwd, 'aparc',\n                                   ['middletemporal-lh', 'middletemporal-rh',\n                                    'superiortemporal-lh', 'superiortemporal-rh'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize the selected data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = evoked.plot(show=False)\nfor ax in fig.get_axes()[:2]:\n    ax.axvline(time_min, color='r', linewidth=2.0)\n    ax.axvline(time_max, color='r', linewidth=2.0)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Apply SESAME.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_sesame = prepare_sesame(fwd, evoked, n_parts=n_parts, noise_std=noise_std,\n                         top_min=time_min, top_max=time_max, dip_mom_std=dip_mom_std,\n                         hyper_q=True, noise_cov=noise_cov, subsample=subsample,\n                         prior_locs=prior_rois, subject=subject, subjects_dir=subjects_dir)\n_sesame.apply_sesame()\n\n# Compute goodness of fit\ngof = _sesame.goodness_of_fit()\nprint('    Goodness of fit with the recorded data: {0}%'.format(round(gof, 4) * 100))\n\n# Compute source dispersion\nsd = _sesame.source_dispersion()\nprint('    Source Dispersion: {0} mm'.format(round(sd, 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize the posterior map of the dipoles' location\n$p(r| \\textbf{y}, 2)$ and the estimated sources on the inflated brain.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_sesame.plot_sources(plot_kwargs={'distance': 650})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize the amplitude of the estimated sources as function of time.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_sesame.plot_source_amplitudes()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# You can save SESAME result in an HDF5 file with:\n# _sesame.save_h5(save_fname, sbj=subject, data_path=fname_evoked, fwd_path=fname_fwd)\n\n# You can save SESAME result in a Pickle file with:\n# _sesame.save_pkl(save_fname, sbj=subject, data_path=fname_evoked, fwd_path=fname_fwd)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}