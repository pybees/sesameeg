{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Compute SESAME inverse solution on evoked data with source constraints\n\nIn this example we shall apply SESAME on an evoked dataset,\ncorresponding to the response to an auditory stimulus. Data are taken from the MNE-Python\n[sample](https://mne.tools/stable/generated/mne.datasets.sample.data_path.html#mne.datasets.sample.data_path)\ndataset. We shall constrain dipole moments to be normal to the cortical surface.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Gianvittorio Luria <luria@dima.unige.it>\n#          Annalisa Pascarella <a.pascarella@iac.cnr.it>\n#          Sara Sommariva <sommariva@dima.unige.it>\n#          Alberto Sorrentino <sorrentino@dima.unige.it>\n#\n# License: BSD (3-clause)\n\n# sphinx_gallery_thumbnail_number = 2\n\nfrom os import path as op\nimport matplotlib.pyplot as plt\n\nfrom mne.datasets import sample\nfrom mne import read_evokeds\nfrom mne import read_forward_solution, convert_forward_solution, pick_types_forward\n\nfrom sesameeg.mne import prepare_sesame\n\ndata_path = sample.data_path()\nsubject = 'sample'\nsubjects_dir = op.join(data_path, 'subjects')\nfname_fwd = op.join(data_path, 'MEG', subject,\n                    'sample_audvis-meg-eeg-oct-6-fwd.fif')\nfname_evoked = op.join(data_path, 'MEG', subject, 'sample_audvis-ave.fif')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the forward solution  $\\textbf{G}$  and the evoked data\n$\\textbf{y}$.\nThe forward solution also defines the employed brain discretization.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "meg_sensor_type = True  # All MEG sensors will be included\neeg_sensor_type = False\n\n# Forward solution\nfwd = read_forward_solution(fname_fwd, exclude='bads')\nfwd = pick_types_forward(fwd, meg=meg_sensor_type,\n                         eeg=eeg_sensor_type, ref_meg=False)\n# Impose cortical orientation constraint\nfwd = convert_forward_solution(fwd, surf_ori=True, force_fixed=True, use_cps=True)\n\n\n# Evoked Data\ncondition = 'Left Auditory'\nevoked = read_evokeds(fname_evoked, condition=condition, baseline=(None, 0))\nevoked = evoked.pick('meg', exclude='bads')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the parameters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "time_min, time_max = 0.045, 0.135  # Select N100m\nsubsample = None\nsample_min, sample_max = evoked.time_as_index([time_min, time_max],\n                                              use_rounding=True)\n\n# To accelerate the run time of this example, we use a small number of\n# particles. We recall that the parameter ``n_parts`` represents, roughly speaking,\n# the number of candidate solutions that are tested in the Monte Carlo procedure;\n# larger values yield in principle more accurate reconstructions but also entail a\n# higher computational cost. Setting the value to about a hundred seems to represent\n# a good trade\u2013off.\nn_parts = 30\n# If None, noise_std and dip_mom_std will be estimated by SESAME.\nnoise_std = None\ndip_mom_std = None\n\n\nnoise_cov = None\n# You can make SESAME pre-whiten the data by providing a noise covariance\n# from mne import read_cov\n# fname_cov = op.join(sample.data_path(), 'MEG', subject,\n#                    'sample_audvis-cov.fif')\n# noise_cov = read_cov(fname_cov)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize the selected data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = evoked.plot(show=False)\nfor ax in fig.get_axes()[:2]:\n    ax.axvline(time_min, color='r', linewidth=2.0)\n    ax.axvline(time_max, color='r', linewidth=2.0)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Apply SESAME.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_sesame = prepare_sesame(fwd, evoked, n_parts=n_parts, noise_std=noise_std,\n                         top_min=time_min, top_max=time_max, dip_mom_std=dip_mom_std,\n                         hyper_q=True, noise_cov=noise_cov, subsample=subsample,\n                         subject=subject, subjects_dir=subjects_dir)\n_sesame.apply_sesame()\n\n# Compute goodness of fit\ngof = _sesame.goodness_of_fit()\nprint('    Goodness of fit with the recorded data: {0}%'.format(round(gof, 4) * 100))\n\n# Compute source dispersion\nsd = _sesame.source_dispersion()\nprint('    Source Dispersion: {0} mm'.format(round(sd, 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize the posterior map of the dipoles' location\n$p(r| \\textbf{y}, 2)$ and the estimated sources on the inflated brain.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_sesame.plot_sources(plot_kwargs={'distance': 650})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize the amplitude of the estimated sources as function of time.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_sesame.plot_source_amplitudes()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# You can save SESAME result in an HDF5 file with:\n# _sesame.save_h5(save_fname, sbj=subject, data_path=fname_evoked, fwd_path=fname_fwd)\n\n# You can save SESAME result in a Pickle file with:\n# _sesame.save_pkl(save_fname, sbj=subject, data_path=fname_evoked, fwd_path=fname_fwd)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}