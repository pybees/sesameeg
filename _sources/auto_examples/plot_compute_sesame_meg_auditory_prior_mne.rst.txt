
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_compute_sesame_meg_auditory_prior_mne.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_compute_sesame_meg_auditory_prior_mne.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_compute_sesame_meg_auditory_prior_mne.py:


===============================================================================
Compute SESAME inverse solution on evoked data with given source location prior
===============================================================================

In this example we shall apply SESAME on an evoked dataset,
corresponding to the response to an auditory stimulus and we manually select a priori source location
probability to reside in a subset of ROIs in a given brain parcellization.
Data are taken from the MNE-Python
`sample <https://mne.tools/stable/generated/mne.datasets.sample.data_path.html#mne.datasets.sample.data_path>`_
dataset.

.. GENERATED FROM PYTHON SOURCE LINES 13-36

.. code-block:: default

    # Authors: Gianvittorio Luria <luria@dima.unige.it>
    #          Sara Sommariva <sommariva@dima.unige.it>
    #          Alberto Sorrentino <sorrentino@dima.unige.it>
    #
    # License: BSD (3-clause)

    # sphinx_gallery_thumbnail_number = 2

    from os import path as op
    import matplotlib.pyplot as plt
    from mne.datasets import sample
    from mne import read_forward_solution, pick_types_forward, read_evokeds
    from sesameeg.utils import prior_loc_from_labels
    from sesameeg.mne import prepare_sesame


    data_path = sample.data_path()
    subject = 'sample'
    subjects_dir = op.join(data_path, 'subjects')
    fname_fwd = op.join(data_path, 'MEG', subject,
                        'sample_audvis-meg-eeg-oct-6-fwd.fif')
    fname_evoked = op.join(data_path, 'MEG', subject, 'sample_audvis-ave.fif')








.. GENERATED FROM PYTHON SOURCE LINES 37-40

Load the forward solution  :math:`\textbf{G}`  and the evoked data
:math:`\textbf{y}`.
The forward solution also defines the employed brain discretization.

.. GENERATED FROM PYTHON SOURCE LINES 40-53

.. code-block:: default

    meg_sensor_type = True  # All MEG sensors will be included
    eeg_sensor_type = False

    # Forward solution
    fwd = read_forward_solution(fname_fwd, exclude='bads')
    fwd = pick_types_forward(fwd, meg=meg_sensor_type,
                             eeg=eeg_sensor_type, ref_meg=False)

    # Evoked Data
    condition = 'Left Auditory'
    evoked = read_evokeds(fname_evoked, condition=condition, baseline=(None, 0))
    evoked = evoked.pick('meg', exclude='bads')





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Reading forward solution from /home/pasca/mne_data/MNE-sample-data/MEG/sample/sample_audvis-meg-eeg-oct-6-fwd.fif...
        Reading a source space...
        Computing patch statistics...
        Patch information added...
        Distance information added...
        [done]
        Reading a source space...
        Computing patch statistics...
        Patch information added...
        Distance information added...
        [done]
        2 source spaces read
        Desired named matrix (kind = 3523) not available
        Read MEG forward solution (7498 sources, 306 channels, free orientations)
        Desired named matrix (kind = 3523) not available
        Read EEG forward solution (7498 sources, 60 channels, free orientations)
        Forward solutions combined: MEG, EEG
        Source spaces transformed to the forward solution coordinate frame
        364 out of 366 channels remain after picking
        305 out of 364 channels remain after picking
    Reading /home/pasca/mne_data/MNE-sample-data/MEG/sample/sample_audvis-ave.fif ...
        Read a total of 4 projection items:
            PCA-v1 (1 x 102) active
            PCA-v2 (1 x 102) active
            PCA-v3 (1 x 102) active
            Average EEG reference (1 x 60) active
        Found the data of interest:
            t =    -199.80 ...     499.49 ms (Left Auditory)
            0 CTF compensation matrices available
            nave = 55 - aspect type = 100
    Projections have already been applied. Setting proj attribute to True.
    Applying baseline correction (mode: mean)
    Removing projector <Projection | Average EEG reference, active : True, n_channels : 60>




.. GENERATED FROM PYTHON SOURCE LINES 54-55

Define the parameters.

.. GENERATED FROM PYTHON SOURCE LINES 55-79

.. code-block:: default

    time_min, time_max = 0.045, 0.135  # Select N100m
    subsample = None
    sample_min, sample_max = evoked.time_as_index([time_min, time_max],
                                                  use_rounding=True)

    # To accelerate the run time of this example, we use a small number of
    # particles. We recall that the parameter ``n_parts`` represents, roughly speaking,
    # the number of candidate solutions that are tested in the Monte Carlo procedure;
    # larger values yield in principle more accurate reconstructions but also entail a
    # higher computational cost. Setting the value to about a hundred seems to represent
    # a good tradeâ€“off.
    n_parts = 10
    # If None, noise_std and dip_mom_std will be estimated by SESAME.
    noise_std = None
    dip_mom_std = None


    noise_cov = None
    # You can make SESAME pre-whiten the data by providing a noise covariance
    # from mne import read_cov
    # fname_cov = op.join(sample.data_path(), 'MEG', subject,
    #                    'sample_audvis-cov.fif')
    # noise_cov = read_cov(fname_cov)








.. GENERATED FROM PYTHON SOURCE LINES 80-81

A priori select some ROIs

.. GENERATED FROM PYTHON SOURCE LINES 81-85

.. code-block:: default

    prior_rois = prior_loc_from_labels(subject, subjects_dir, fwd, 'aparc',
                                       ['middletemporal-lh', 'middletemporal-rh',
                                        'superiortemporal-lh', 'superiortemporal-rh'])





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Reading labels from parcellation...
       read 34 labels from /home/pasca/mne_data/MNE-sample-data/subjects/sample/label/lh.aparc.annot
       read 34 labels from /home/pasca/mne_data/MNE-sample-data/subjects/sample/label/rh.aparc.annot




.. GENERATED FROM PYTHON SOURCE LINES 86-87

Visualize the selected data.

.. GENERATED FROM PYTHON SOURCE LINES 87-94

.. code-block:: default


    fig = evoked.plot(show=False)
    for ax in fig.get_axes()[:2]:
        ax.axvline(time_min, color='r', linewidth=2.0)
        ax.axvline(time_max, color='r', linewidth=2.0)
    plt.show()




.. image-sg:: /auto_examples/images/sphx_glr_plot_compute_sesame_meg_auditory_prior_mne_001.png
   :alt: Gradiometers (203 channels), Magnetometers (102 channels)
   :srcset: /auto_examples/images/sphx_glr_plot_compute_sesame_meg_auditory_prior_mne_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 95-96

Apply SESAME.

.. GENERATED FROM PYTHON SOURCE LINES 96-110

.. code-block:: default

    _sesame = prepare_sesame(fwd, evoked, n_parts=n_parts, noise_std=noise_std,
                             top_min=time_min, top_max=time_max, dip_mom_std=dip_mom_std,
                             hyper_q=True, noise_cov=noise_cov, subsample=subsample,
                             prior_locs=prior_rois, subject=subject, subjects_dir=subjects_dir)
    _sesame.apply_sesame()

    # Compute goodness of fit
    gof = _sesame.goodness_of_fit()
    print('    Goodness of fit with the recorded data: {0}%'.format(round(gof, 4) * 100))

    # Compute source dispersion
    sd = _sesame.source_dispersion()
    print('    Source Dispersion: {0} mm'.format(round(sd, 2)))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Computing inverse operator with 305 channels.
        305 out of 305 channels remain after picking
    Forward model with free source orientation.
    Computing neighbours matrix [done]
    Computing neighbours probabilities...[done]
    Analyzing data from 0.045 s to 0.1349 s
    Sampling user defined prior probability distribution for dipole locations.
    Estimating dipole moment std...[done]
     Estimated dipole moment std: 3.2335e-08
    Sampling hyperprior for dipole moment std.
    Estimating noise std...[done]
     Estimated noise std: 3.9983e-12
    Computing inverse solution. This will take a while...
        Estimated dipole strength variance: 3.1238631691286244e-08
        Estimated number of sources: 2
        Estimated source locations:
            * source 1: [0.04589902 0.00942308 0.06544629]
            * source 2: [-0.05817005  0.00491732  0.05770831]
    [done in 107 iterations]
        Goodness of fit with the recorded data: 69.95%
        Source Dispersion: 0.0 mm




.. GENERATED FROM PYTHON SOURCE LINES 111-113

Visualize the posterior map of the dipoles' location
:math:`p(r| \textbf{y}, 2)` and the estimated sources on the inflated brain.

.. GENERATED FROM PYTHON SOURCE LINES 113-115

.. code-block:: default

    _sesame.plot_sources()




.. image-sg:: /auto_examples/images/sphx_glr_plot_compute_sesame_meg_auditory_prior_mne_002.png
   :alt: plot compute sesame meg auditory prior mne
   :srcset: /auto_examples/images/sphx_glr_plot_compute_sesame_meg_auditory_prior_mne_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Surface stc computed.




.. GENERATED FROM PYTHON SOURCE LINES 116-117

Visualize the amplitude of the estimated sources as function of time.

.. GENERATED FROM PYTHON SOURCE LINES 117-119

.. code-block:: default

    _sesame.plot_source_amplitudes()




.. image-sg:: /auto_examples/images/sphx_glr_plot_compute_sesame_meg_auditory_prior_mne_003.png
   :alt: plot compute sesame meg auditory prior mne
   :srcset: /auto_examples/images/sphx_glr_plot_compute_sesame_meg_auditory_prior_mne_003.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 120-121

Save results.

.. GENERATED FROM PYTHON SOURCE LINES 121-127

.. code-block:: default


    # You can save SESAME result in an HDF5 file with:
    # _sesame.save_h5(save_fname, sbj=subject, data_path=fname_evoked, fwd_path=fname_fwd)

    # You can save SESAME result in a Pickle file with:
    # _sesame.save_pkl(save_fname, sbj=subject, data_path=fname_evoked, fwd_path=fname_fwd)








.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 22.844 seconds)


.. _sphx_glr_download_auto_examples_plot_compute_sesame_meg_auditory_prior_mne.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example




    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_compute_sesame_meg_auditory_prior_mne.py <plot_compute_sesame_meg_auditory_prior_mne.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_compute_sesame_meg_auditory_prior_mne.ipynb <plot_compute_sesame_meg_auditory_prior_mne.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
